{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project Submission\n",
    "\n",
    "Please fill out:\n",
    "* Student name: Charlie Losche\n",
    "* Student pace: full time\n",
    "* Scheduled project review date/time: 8/1/2022\n",
    "* Instructor name: David Elliot\n",
    "* Blog post URL:N/A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - remember to use markdown cells for comments as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from mpl_toolkits import mplot3d\n",
    "import sklearn.metrics as metrics\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempting Sklearn predictive model with our current regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alira\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\alira\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/kc_house_data.csv',\n",
    "                parse_dates=['date'])\n",
    "\n",
    "df.drop(['id', 'floors',\n",
    "         'heat_source','lat','long'], axis=1, inplace=True)\n",
    "\n",
    "# Create zip from address\n",
    "df['zip'] = [x.split(',')[2][-5:] for x in df['address']] \n",
    "\n",
    "#https://www.zillow.com/browse/homes/wa/king-county/  - remove all records with zipcodes that dont start with '98'\n",
    "df = df[df.zip.str.startswith(('98'))]\n",
    "\n",
    "df['city'] = [x.split(',')[1][0:] for x in df['address']]\n",
    "\n",
    "#create sale year column from datetime date info\n",
    "df['sale_year'] = pd.DatetimeIndex(df['date']).year.astype(int)\n",
    "\n",
    "df['sale_year'].value_counts()\n",
    "\n",
    "\n",
    "#create new column - age of house\n",
    "df['home_age'] = (df['sale_year']+1) - df['yr_built']\n",
    "\n",
    "#create new column - time since reno\n",
    "df['yr_from_reno'] = (df['sale_year']+1) - df['yr_renovated']\n",
    "\n",
    "# create filter for yr_from_reno to ID houses that haven't been renovated\n",
    "reno_filter = df['yr_from_reno'] > 2000\n",
    "\n",
    "# create new column for design_age to see time since build if no reno, or time since reno if renovated\n",
    "# first set to reno age\n",
    "df['design_age'] = df['yr_from_reno']\n",
    "#then update columns where there was no reno to age of the home\n",
    "df['design_age'].loc[reno_filter] = df['home_age']\n",
    "\n",
    "#some houses were sold before they were built - we need to change those records to 0\n",
    "\n",
    "prebuild_filter = df['design_age'] < 1\n",
    "\n",
    "df['design_age'].loc[prebuild_filter] = 1\n",
    "\n",
    "\n",
    "grade_cat = df[['grade']]\n",
    "grade_categories = ['1 Cabin', '2 Substandard', '3 Poor', '4 Low', '5 Fair', '6 Low Average',\n",
    "                    '7 Average', '8 Good', '9 Better', '10 Very Good', '11 Excellent', '12 Luxury', '13 Mansion']\n",
    "encoder_grade = OrdinalEncoder(categories=[grade_categories])\n",
    "encoder_grade.fit(grade_cat)\n",
    "grade_encoded_train = encoder_grade.transform(grade_cat)\n",
    "grade_encoded_train = grade_encoded_train.flatten()\n",
    "df[\"grade\"] = grade_encoded_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['city'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updating the df to only include homes tham meet minimum code requirements - Average grade of construction and design, and up to homes where finish work is better and more design quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_filter1 = df[\"grade\"] > 5 \n",
    "grade_filter2 = df[\"grade\"] < 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[grade_filter1 & grade_filter2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['city'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Seattle            8081\n",
       " Renton             1633\n",
       " Kent               1466\n",
       " Bellevue           1417\n",
       " Auburn             1288\n",
       "                    ... \n",
       " Snoqualmie Pass       1\n",
       " Dilworth              1\n",
       " Lakeland North        1\n",
       " Snohomish             1\n",
       " Cottage Lake          1\n",
       "Name: city, Length: 61, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['city'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_city = df.groupby('city').count()['price'].reset_index()\n",
    "city_columns = df_city[ df_city['price'] >= 30 ].transpose()\n",
    "city_columns.columns = city_columns.iloc[0]\n",
    "len(city_columns.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([' Algona', ' Ames Lake', ' Arlington', ' Beaux Arts', ' Cottage Lake',\n",
       "       ' Dash Point', ' Dilworth', ' Eatonville', ' Fairwood', ' Hobart',\n",
       "       ' Hunts Point', ' Lakeland North', ' Marysville', ' Milton', ' Monroe',\n",
       "       ' Preston', ' Puyallup', ' Skykomish', ' Snohomish', ' Snoqualmie Pass',\n",
       "       ' Spanaway', ' Tulalip', ' Union Hill-Novelty Hill', ' Vancouver',\n",
       "       ' Yarrow Point'],\n",
       "      dtype='object', name='city')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_city = df.groupby('city').count()['price'].reset_index()\n",
    "drop_city_columns = drop_city[ drop_city['price'] < 30 ].transpose()\n",
    "drop_city_columns.columns = drop_city_columns.iloc[0]\n",
    "drop_city_columns.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>city</th>\n",
       "      <th>Algona</th>\n",
       "      <th>Ames Lake</th>\n",
       "      <th>Arlington</th>\n",
       "      <th>Beaux Arts</th>\n",
       "      <th>Cottage Lake</th>\n",
       "      <th>Dash Point</th>\n",
       "      <th>Dilworth</th>\n",
       "      <th>Eatonville</th>\n",
       "      <th>Fairwood</th>\n",
       "      <th>Hobart</th>\n",
       "      <th>...</th>\n",
       "      <th>Preston</th>\n",
       "      <th>Puyallup</th>\n",
       "      <th>Skykomish</th>\n",
       "      <th>Snohomish</th>\n",
       "      <th>Snoqualmie Pass</th>\n",
       "      <th>Spanaway</th>\n",
       "      <th>Tulalip</th>\n",
       "      <th>Union Hill-Novelty Hill</th>\n",
       "      <th>Vancouver</th>\n",
       "      <th>Yarrow Point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <td>Algona</td>\n",
       "      <td>Ames Lake</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>Beaux Arts</td>\n",
       "      <td>Cottage Lake</td>\n",
       "      <td>Dash Point</td>\n",
       "      <td>Dilworth</td>\n",
       "      <td>Eatonville</td>\n",
       "      <td>Fairwood</td>\n",
       "      <td>Hobart</td>\n",
       "      <td>...</td>\n",
       "      <td>Preston</td>\n",
       "      <td>Puyallup</td>\n",
       "      <td>Skykomish</td>\n",
       "      <td>Snohomish</td>\n",
       "      <td>Snoqualmie Pass</td>\n",
       "      <td>Spanaway</td>\n",
       "      <td>Tulalip</td>\n",
       "      <td>Union Hill-Novelty Hill</td>\n",
       "      <td>Vancouver</td>\n",
       "      <td>Yarrow Point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "city    Algona   Ames Lake   Arlington   Beaux Arts   Cottage Lake  \\\n",
       "city    Algona   Ames Lake   Arlington   Beaux Arts   Cottage Lake   \n",
       "price       25           1           4           10              1   \n",
       "\n",
       "city    Dash Point   Dilworth   Eatonville   Fairwood   Hobart  ...   Preston  \\\n",
       "city    Dash Point   Dilworth   Eatonville   Fairwood   Hobart  ...   Preston   \n",
       "price            1          1            2          1        4  ...         4   \n",
       "\n",
       "city    Puyallup   Skykomish   Snohomish   Snoqualmie Pass   Spanaway  \\\n",
       "city    Puyallup   Skykomish   Snohomish   Snoqualmie Pass   Spanaway   \n",
       "price          2           6           1                 1          2   \n",
       "\n",
       "city    Tulalip   Union Hill-Novelty Hill   Vancouver   Yarrow Point  \n",
       "city    Tulalip   Union Hill-Novelty Hill   Vancouver   Yarrow Point  \n",
       "price         4                         2           2              8  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_city_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Algona',\n",
       " ' Ames Lake',\n",
       " ' Arlington',\n",
       " ' Beaux Arts',\n",
       " ' Cottage Lake',\n",
       " ' Dash Point',\n",
       " ' Dilworth',\n",
       " ' Eatonville',\n",
       " ' Fairwood',\n",
       " ' Hobart',\n",
       " ' Hunts Point',\n",
       " ' Lakeland North',\n",
       " ' Marysville',\n",
       " ' Milton',\n",
       " ' Monroe',\n",
       " ' Preston',\n",
       " ' Puyallup',\n",
       " ' Skykomish',\n",
       " ' Snohomish',\n",
       " ' Snoqualmie Pass',\n",
       " ' Spanaway',\n",
       " ' Tulalip',\n",
       " ' Union Hill-Novelty Hill',\n",
       " ' Vancouver',\n",
       " ' Yarrow Point']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_city = list(drop_city_columns.columns)\n",
    "\n",
    "drop_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25777"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we remove all home sales in cities that had less than a total of 30 sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in drop_city:\n",
    "    df = df[~df.city.str.contains(city)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25655"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updating the df to only include homes tham meet minimum code requirements - Average grade of construction and design, and up to homes where finish work is better and more design quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['city'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning data to sqft living over 500 sqft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.seattle.gov/Documents/Departments/SDCI/Codes/SingleFamilyZoningSummary.pdf\n",
    "\n",
    "https://getjerry.com/questions/how-many-square-feet-is-a-2-car-garage\n",
    "\n",
    "According to the zoning proposal above, small, single family (larger cottage style) homes have a total square feet of 1,400 - assuming garage is the only non-living area, and the average 2 car garage is 360 sqft (from Jerry above)\n",
    "\n",
    "- minimim living sqft should be 1000 (giving extra flex room for garage)\n",
    "\n",
    "Given the fact that we're not building mansions, just single family homes, if we build detached homes with total area of 2200 sqft, we'd get access to the FAR preservation incentive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25655"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqft_filter1 = df[\"sqft_living\"] > 1100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[sqft_filter1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24257"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"price\"]\n",
    "X = df.drop(\"price\", axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train is a DataFrame with 18192 rows and 25 columns\n",
      "y_train is a Series with 18192 values\n",
      "X_test is a DataFrame with 6065 rows and 25 columns\n",
      "y_test is a Series with 6065 values\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train is a DataFrame with {X_train.shape[0]} rows and {X_train.shape[1]} columns\")\n",
    "print(f\"y_train is a Series with {y_train.shape[0]} values\")\n",
    "\n",
    "print(f\"X_test is a DataFrame with {X_test.shape[0]} rows and {X_test.shape[1]} columns\")\n",
    "print(f\"y_test is a Series with {y_test.shape[0]} values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Poor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-27d20e939e9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mcondition_categories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Poor'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Fair'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Average'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Good'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Very Good'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mencoder_condition\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOrdinalEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcondition_categories\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mencoder_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcondition_cat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[0mcondition_encoded_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcondition_cat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mcondition_encoded_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcondition_encoded_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    680\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m         \"\"\"\n\u001b[1;32m--> 682\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    683\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, handle_unknown)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mcats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 \u001b[0mcats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mXi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mXi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcats\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Poor'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Quasi-categorical(0.5 + 0.5 bathrooms != 1 bathroom). Change 0 bathroom to 1 bathroom. Round up other values.\n",
    "X_train.loc[X_train['bathrooms'] == 0, 'bathrooms'] = 1\n",
    "X_train['bathrooms'] = X_train['bathrooms'].apply(np.ceil)\n",
    "\n",
    "\n",
    "# Create binary substitutes for columns\n",
    "X_train['basement_binary'] = [1 if sq >  0  else 0 for sq in X_train['sqft_basement']]\n",
    "X_train['garage_binary'] = [1 if sq >  0  else 0 for sq in X_train['sqft_garage']]\n",
    "X_train['patio_binary'] = [1 if sq >  0  else 0 for sq in X_train['sqft_patio']]\n",
    "X_train['waterfront_binary'] = [1 if sq == 'YES'  else 0 for sq in X_train['waterfront']]\n",
    "X_train['PublicSewer_binary'] = [1 if sq == 'PUBLIC' else 0 for sq in X_train['sewer_system']]\n",
    "X_train['yrenovated_binary'] = [1 if sq >  0 else 0 for sq in X_train['yr_renovated']]\n",
    "\n",
    "\n",
    "# Create binary values for greenbelt, nuisance\n",
    "\n",
    "nuisance_cat = X_train[['nuisance']]\n",
    "encoder_nuisance = OrdinalEncoder()\n",
    "encoder_nuisance.fit(nuisance_cat)\n",
    "nuisance_encoded_train = encoder_nuisance.transform(nuisance_cat)\n",
    "nuisance_encoded_train = nuisance_encoded_train.flatten()\n",
    "X_train[\"nuisance\"] = nuisance_encoded_train\n",
    "\n",
    "# Create Ordinal Values for condition\n",
    "# Using OneHotEncoder\n",
    "condition_cat = X_train[['condition']]\n",
    "condition_categories = ['Poor', 'Fair', 'Average', 'Good', 'Very Good']\n",
    "encoder_condition = OrdinalEncoder(categories=[condition_categories])\n",
    "encoder_condition.fit(condition_cat)\n",
    "condition_encoded_train = encoder_condition.transform(condition_cat)\n",
    "condition_encoded_train = condition_encoded_train.flatten()\n",
    "X_train[\"condition\"] = condition_encoded_train\n",
    "\n",
    "# Create Ordinal Values for view\n",
    "# Using OneHotEncoder\n",
    "view_cat = X_train[['view']]\n",
    "view_categories = ['NONE', 'FAIR', 'AVERAGE', 'GOOD', 'EXCELLENT']\n",
    "encoder_view = OrdinalEncoder(categories=[view_categories])\n",
    "encoder_view.fit(view_cat)\n",
    "view_encoded_train = encoder_view.transform(view_cat)\n",
    "view_encoded_train = view_encoded_train.flatten()\n",
    "X_train[\"view\"] = view_encoded_train\n",
    "\n",
    "\n",
    "# extracted from df\n",
    "# (double brackets due to shape expected by OHE)\n",
    "city_train = X_train[[\"city\"]]\n",
    "\n",
    "ohe_city = OneHotEncoder(categories=\"auto\",\n",
    "                    sparse=False,\n",
    "                    handle_unknown=\"ignore\")\n",
    "\n",
    "# (3) Fit the encoder on fireplace_qu_train\n",
    "ohe_city.fit(city_train)\n",
    "\n",
    "# (2) Instantiate a OneHotEncoder with categories=\"auto\",\n",
    "# sparse=False, and handle_unknown=\"ignore\"\n",
    "city_encoded_train = ohe_city.transform(city_train)\n",
    "\n",
    "# Visually inspect fireplace_qu_encoded_train\n",
    "city_encoded_train\n",
    "\n",
    "# (5a) Make the transformed data into a dataframe\n",
    "city_encoded_train = pd.DataFrame(\n",
    "    # Pass in NumPy array\n",
    "    city_encoded_train,\n",
    "    # Set the column names to the categories found by OHE\n",
    "    columns=ohe_city.categories_[0],\n",
    "    # Set the index to match X_test's index\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "# (5b) Drop original FireplaceQu column\n",
    "X_train.drop(\"city\", axis=1, inplace=True)\n",
    "\n",
    "# (5c) Concatenate the new dataframe with current X_train\n",
    "X_train = pd.concat([X_train, city_encoded_train], axis=1)\n",
    "\n",
    "\n",
    "# Create 'total_sqft' by combining sqft_above + sqft_basement + \n",
    "# sqft_garage + sqft_patio\n",
    "X_train['total_sqft'] = X_train['sqft_above'] + X_train['sqft_basement'] + X_train['sqft_garage'] + X_train['sqft_patio']\n",
    "\n",
    "X_train['weighted__livsqft'] = X_train['sqft_living'] * X_train['grade']\n",
    "\n",
    "X_train['date'] = pd.to_datetime(X_train['date'], format='%Y-%m-%d')\n",
    "\n",
    "X_train['date'].head()\n",
    "\n",
    "#create sale year column from datetime date info\n",
    "X_train['sale_year'] = pd.DatetimeIndex(X_train['date']).year.astype(int)\n",
    "\n",
    "X_train['sale_year'].value_counts()\n",
    "\n",
    "#Binning by decade\n",
    "\n",
    "X_train['design_decade'] = pd.cut(x=X_train['design_age'], bins=[0, 3, 13, 23, 33, 43, 53, 63, 73,\n",
    "                                                         83, 93, 103, 113, 123],\n",
    "                    labels=['2020s', '2010s', '2000s', '1990s', '1980s', '1970s', '1960s',\n",
    "                            '1950s', '1940s', '1930s', '1920s', '1910s', '1900s'])\n",
    "\n",
    "X_train.design_decade.value_counts()\n",
    "\n",
    "labels_ordered = ['2020s', '2010s', '2000s', '1990s', '1980s', '1970s', '1960s','1950s', '1940s', '1930s', '1920s', '1910s', '1900s']\n",
    "\n",
    "labels_ordered.reverse()\n",
    "\n",
    "labels_ordered\n",
    "\n",
    "# Create Ordinal Values for view\n",
    "# Using OneHotEncoder\n",
    "age_cat = X_train[['design_decade']]\n",
    "age_categories = labels_ordered\n",
    "encoder_age = OrdinalEncoder(categories=[age_categories])\n",
    "encoder_age.fit(age_cat)\n",
    "encoder_age.categories_[0]\n",
    "\n",
    "age_encoded_train = encoder_age.transform(age_cat)\n",
    "age_encoded_train = age_encoded_train.flatten()\n",
    "X_train[\"design_decade\"] = age_encoded_train\n",
    "\n",
    "X_train[\"design_decade\"]\n",
    "\n",
    "X_train['yard_size_ratio'] = (X_train['total_sqft'] / X_train['sqft_lot']) * 100\n",
    "\n",
    "list(X_train.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['view_grade'] = (X_train['view'] + 1) * X_train['grade']\n",
    "X_train['waterfront_grade'] = (X_train['waterfront_binary'] + 1)  * X_train['grade']\n",
    "X_train['design_decade_grade'] = (X_train['design_decade'] + 1)  * X_train['grade']\n",
    "X_train['nuisance_grade'] = (X_train['nuisance'] + 1)  * X_train['grade']\n",
    "X_train['garage_binary_grade'] = (X_train['garage_binary'] + 1)  * X_train['grade']\n",
    "X_train['basement_binary_grade'] = (X_train['basement_binary'] + 1)  * X_train['grade']\n",
    "X_train['patio_binary_grade'] = (X_train['patio_binary'] + 1)  * X_train['grade']\n",
    "X_train['PublicSewer_binary_grade'] = (X_train['PublicSewer_binary'] + 1)  * X_train['grade']\n",
    "X_train['condition_grade'] = (X_train['condition'] + 1)  * X_train['grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant = [' Auburn', ' Bellevue', ' Black Diamond', ' Bothell', ' Burien',\n",
    "           ' Carnation', ' Clyde Hill', ' Covington', ' Des Moines', ' Duvall',\n",
    "           ' Enumclaw', ' Fall City', ' Federal Way', ' Issaquah', ' Kenmore',\n",
    "           ' Kent', ' Kirkland', ' Lake Forest Park', ' Maple Valley', ' Medina',\n",
    "           ' Mercer Island', ' Newcastle', ' Normandy Park', ' North Bend',\n",
    "           ' Pacific', ' Ravensdale', ' Redmond', ' Renton', ' Sammamish',\n",
    "           ' SeaTac', ' Seattle', ' Shoreline', ' Snoqualmie', ' Tukwila',\n",
    "           ' Vashon', ' Woodinville',\n",
    "            'weighted__livsqft', 'design_decade', 'yard_size_ratio', 'view_grade',\n",
    "            'waterfront_grade', 'design_decade_grade', 'nuisance_grade', 'garage_binary_grade',\n",
    "            'basement_binary_grade', 'patio_binary_grade', 'PublicSewer_binary_grade', 'condition_grade']\n",
    "\n",
    "X_train1 = X_train[relevant]\n",
    "\n",
    "X_train = X_train[relevant]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.view_grade.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train = sm.OLS(y_train, sm.add_constant(X_train)).fit()\n",
    "results_train = model_train.summary()\n",
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quasi-categorical(0.5 + 0.5 bathrooms != 1 bathroom). Change 0 bathroom to 1 bathroom. Round up other values.\n",
    "X_test.loc[X_test['bathrooms'] == 0, 'bathrooms'] = 1\n",
    "X_test['bathrooms'] = X_test['bathrooms'].apply(np.ceil)\n",
    "\n",
    "\n",
    "# Create binary substitutes for columns\n",
    "X_test['basement_binary'] = [1 if sq >  0  else 0 for sq in X_test['sqft_basement']]\n",
    "X_test['garage_binary'] = [1 if sq >  0  else 0 for sq in X_test['sqft_garage']]\n",
    "X_test['patio_binary'] = [1 if sq >  0  else 0 for sq in X_test['sqft_patio']]\n",
    "X_test['waterfront_binary'] = [1 if sq == 'YES'  else 0 for sq in X_test['waterfront']]\n",
    "X_test['PublicSewer_binary'] = [1 if sq == 'PUBLIC' else 0 for sq in X_test['sewer_system']]\n",
    "X_test['yrenovated_binary'] = [1 if sq >  0 else 0 for sq in X_test['yr_renovated']]\n",
    "\n",
    "\n",
    "# Create binary values for greenbelt, nuisance\n",
    "# Using OneHotEncoder\n",
    "\n",
    "greenbelt_cat = X_test[['greenbelt']]\n",
    "greenbelt_encoded_train = encoder_greenbelt.transform(greenbelt_cat)\n",
    "greenbelt_encoded_train = greenbelt_encoded_train.flatten()\n",
    "# greenbelt_encoded_train\n",
    "X_test[\"greenbelt\"] = greenbelt_encoded_train\n",
    "\n",
    "nuisance_cat = X_test[['nuisance']]\n",
    "nuisance_encoded_train = encoder_nuisance.transform(nuisance_cat)\n",
    "nuisance_encoded_train = nuisance_encoded_train.flatten()\n",
    "X_test[\"nuisance\"] = nuisance_encoded_train\n",
    "\n",
    "# Create Ordinal Values for condition\n",
    "# Using OneHotEncoder\n",
    "condition_cat = X_test[['condition']]\n",
    "condition_encoded_train = encoder_condition.transform(condition_cat)\n",
    "condition_encoded_train = condition_encoded_train.flatten()\n",
    "X_test[\"condition\"] = condition_encoded_train\n",
    "\n",
    "# Create Ordinal Values for view\n",
    "# Using OneHotEncoder\n",
    "view_cat = X_test[['view']]\n",
    "view_encoded_train = encoder_view.transform(view_cat)\n",
    "view_encoded_train = view_encoded_train.flatten()\n",
    "X_test[\"view\"] = view_encoded_train\n",
    "\n",
    "\n",
    "# (1) Create a variable zip\n",
    "# extracted from df\n",
    "# (double brackets due to shape expected by OHE)\n",
    "city_train = X_test[[\"city\"]]\n",
    "\n",
    "city_encoded_train = ohe_city.transform(city_train)\n",
    "\n",
    "# Visually inspect fireplace_qu_encoded_train\n",
    "city_encoded_train\n",
    "\n",
    "# (5a) Make the transformed data into a dataframe\n",
    "city_encoded_train = pd.DataFrame(\n",
    "    # Pass in NumPy array\n",
    "    city_encoded_train,\n",
    "    # Set the column names to the categories found by OHE\n",
    "    columns=ohe_city.categories_[0],\n",
    "    # Set the index to match X_test's index\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "# Run this cell without changes\n",
    "\n",
    "# (5b) Drop original FireplaceQu column\n",
    "X_test.drop(\"city\", axis=1, inplace=True)\n",
    "\n",
    "# Run this cell without changes\n",
    "\n",
    "# (5c) Concatenate the new dataframe with current X_test\n",
    "X_test = pd.concat([X_test, city_encoded_train], axis=1)\n",
    "\n",
    "# Visually inspect X_test\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# (1) Create a variable zip\n",
    "# extracted from df\n",
    "# (double brackets due to shape expected by OHE)\n",
    "fireplace_qu_train = X_test[[\"zip\"]]\n",
    "\n",
    "# Replace None with appropriate code\n",
    "\n",
    "# (4) Transform fireplace_qu_train using the encoder and\n",
    "# assign the result to fireplace_qu_encoded_train\n",
    "fireplace_qu_encoded_train = ohe_zip.transform(fireplace_qu_train)\n",
    "\n",
    "# Visually inspect fireplace_qu_encoded_train\n",
    "fireplace_qu_encoded_train\n",
    "\n",
    "# Run this cell without changes\n",
    "\n",
    "# (5a) Make the transformed data into a dataframe\n",
    "fireplace_qu_encoded_train = pd.DataFrame(\n",
    "    # Pass in NumPy array\n",
    "    fireplace_qu_encoded_train,\n",
    "    # Set the column names to the categories found by OHE\n",
    "    columns=ohe_zip.categories_[0],\n",
    "    # Set the index to match X_test's index\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "# Visually inspect new dataframe\n",
    "fireplace_qu_encoded_train\n",
    "\n",
    "# Run this cell without changes\n",
    "\n",
    "# (5b) Drop original FireplaceQu column\n",
    "X_test.drop(\"zip\", axis=1, inplace=True)\n",
    "\n",
    "# Visually inspect X_test\n",
    "\n",
    "# Run this cell without changes\n",
    "\n",
    "# (5c) Concatenate the new dataframe with current X_test\n",
    "X_test = pd.concat([X_test, fireplace_qu_encoded_train], axis=1)\n",
    "\n",
    "# Visually inspect X_test\n",
    "X_test.head()\n",
    "\n",
    "# Create 'total_sqft' by combining sqft_above + sqft_basement + \n",
    "# sqft_garage + sqft_patio\n",
    "X_test['total_sqft'] = X_test['sqft_above'] + X_test['sqft_basement'] + X_test['sqft_garage'] + X_test['sqft_patio']\n",
    "\n",
    "X_test['weighted__livsqft'] = X_test['sqft_living'] * X_test['grade']\n",
    "\n",
    "X_test['date'] = pd.to_datetime(X_test['date'], format='%Y-%m-%d')\n",
    "\n",
    "X_test['date'].head()\n",
    "\n",
    "#create sale year column from datetime date info\n",
    "X_test['sale_year'] = pd.DatetimeIndex(X_test['date']).year.astype(int)\n",
    "\n",
    "X_test['sale_year'].value_counts()\n",
    "\n",
    "#Binning by decade\n",
    "\n",
    "X_test['design_decade'] = pd.cut(x=X_test['design_age'], bins=[0, 3, 13, 23, 33, 43, 53, 63, 73,\n",
    "                                                         83, 93, 103, 113, 123],\n",
    "                    labels=['2020s', '2010s', '2000s', '1990s', '1980s', '1970s', '1960s',\n",
    "                            '1950s', '1940s', '1930s', '1920s', '1910s', '1900s'])\n",
    "\n",
    "X_test.design_decade.value_counts()\n",
    "\n",
    "labels_ordered = ['2020s', '2010s', '2000s', '1990s', '1980s', '1970s', '1960s','1950s', '1940s', '1930s', '1920s', '1910s', '1900s']\n",
    "\n",
    "labels_ordered.reverse()\n",
    "\n",
    "labels_ordered\n",
    "\n",
    "# Create Ordinal Values for view\n",
    "# Using OneHotEncoder\n",
    "age_cat = X_test[['design_decade']]\n",
    "age_categories = labels_ordered\n",
    "age_encoded_train = encoder_age.transform(age_cat)\n",
    "age_encoded_train = age_encoded_train.flatten()\n",
    "X_test[\"design_decade\"] = age_encoded_train\n",
    "\n",
    "X_test[\"design_decade\"]\n",
    "\n",
    "X_test['yard_size_ratio'] = (X_test['total_sqft'] / X_test['sqft_lot']) * 100\n",
    "\n",
    "list(X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['view_grade'] = (X_test['view'] + 1) * X_test['grade']\n",
    "X_test['waterfront_grade'] = (X_test['waterfront_binary'] + 1)  * X_test['grade']\n",
    "X_test['design_decade_grade'] = (X_test['design_decade'] + 1)  * X_test['grade']\n",
    "X_test['nuisance_grade'] = (X_test['nuisance'] + 1)  * X_test['grade']\n",
    "X_test['garage_binary_grade'] = (X_test['garage_binary'] + 1)  * X_test['grade']\n",
    "X_test['basement_binary_grade'] = (X_test['basement_binary'] + 1)  * X_test['grade']\n",
    "X_test['patio_binary_grade'] = (X_test['patio_binary'] + 1)  * X_test['grade']\n",
    "X_test['PublicSewer_binary_grade'] = (X_test['PublicSewer_binary'] + 1)  * X_test['grade']\n",
    "X_test['condition_grade'] = (X_test['condition'] + 1)  * X_test['grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant = [' Auburn', ' Bellevue', ' Black Diamond', ' Bothell', ' Burien',\n",
    "           ' Carnation', ' Clyde Hill', ' Covington', ' Des Moines', ' Duvall',\n",
    "           ' Enumclaw', ' Fall City', ' Federal Way', ' Issaquah', ' Kenmore',\n",
    "           ' Kent', ' Kirkland', ' Lake Forest Park', ' Maple Valley', ' Medina',\n",
    "           ' Mercer Island', ' Newcastle', ' Normandy Park', ' North Bend',\n",
    "           ' Pacific', ' Ravensdale', ' Redmond', ' Renton', ' Sammamish',\n",
    "           ' SeaTac', ' Seattle', ' Shoreline', ' Snoqualmie', ' Tukwila',\n",
    "           ' Vashon', ' Woodinville',\n",
    "            'weighted__livsqft', 'design_decade', 'yard_size_ratio', 'view_grade',\n",
    "            'waterfront_grade', 'design_decade_grade', 'nuisance_grade', 'garage_binary_grade',\n",
    "            'basement_binary_grade', 'patio_binary_grade', 'PublicSewer_binary_grade', 'condition_grade']\n",
    "\n",
    "X_test = X_test[relevant]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant = ['view', 'condition', ' Auburn', ' Bellevue', ' Black Diamond', ' Bothell', ' Burien',\n",
    "#            ' Carnation', ' Clyde Hill', ' Covington', ' Des Moines', ' Duvall',\n",
    "#            ' Enumclaw', ' Fall City', ' Federal Way', ' Issaquah', ' Kenmore',\n",
    "#            ' Kent', ' Kirkland', ' Lake Forest Park', ' Maple Valley', ' Medina',\n",
    "#            ' Mercer Island', ' Newcastle', ' Normandy Park', ' North Bend',\n",
    "#            ' Pacific', ' Ravensdale', ' Redmond', ' Renton', ' Sammamish',\n",
    "#            ' SeaTac', ' Seattle', ' Shoreline', ' Snoqualmie', ' Tukwila',\n",
    "#            ' Vashon', ' Woodinville', 'weighted__livsqft', 'design_decade', 'nuisance','garage_binary',\n",
    "#             'basement_binary', 'patio_binary','PublicSewer_binary', 'waterfront_binary', 'yard_size_ratio', 'grade']\n",
    "\n",
    "# X_test = X_test[relevant]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = sm.OLS(y_test, sm.add_constant(X_test)).fit()\n",
    "results_test = model_test.summary()\n",
    "results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Based Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive Statistices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('the Mean price for Train is:', y_train.mean())\n",
    "print('the Mean price for Test is:', y_test.mean())\n",
    "print()\n",
    "print('the standard deviation in price for Train is:', y_train.std())\n",
    "print('the standard deviation in price for Test is:', y_test.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('the adjusted R-squared value for Train is:', model_train.rsquared_adj)\n",
    "print('the adjusted R-squared value for Test is:', model_test.rsquared_adj)\n",
    "print()\n",
    "print('the F-statistic p-value for Train is:', model_train.f_pvalue)\n",
    "print('the F-statistic p-value for Test is:', model_test.f_pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R Squared and P value Interpretation**\n",
    "\n",
    "With an adjusted R2 for both train and test at .643 and .692 respectively, our model explains 64% to 69% of the variance in price\n",
    "\n",
    "As for the P values of the F statistic, both our training and testing datasets have shown that our model has statistical significance, we reject the Null that our model's features have no impact on price (target variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mae = model_train.resid.abs().sum() / len(y_train)\n",
    "test_mae = model_test.resid.abs().sum() / len(y_test)\n",
    "print('the Mean Absolute Error for Train is:', train_mae)\n",
    "print('the Mean Absolute Error for Test is:', test_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse = ((model_train.resid ** 2).sum() / len(y_train)) ** 0.5\n",
    "test_rmse = ((model_test.resid ** 2).sum() / len(y_test)) ** 0.5\n",
    "print('the Root Mean Squared Error for Train is:', train_rmse)\n",
    "print('the Root Mean Squared Error for Test is:', test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MAE Interpretation**\n",
    "\n",
    "For this specific MAE evaluation, the MEA scores mean that our model is off by about $270k dollars on a given prediction on the price.\n",
    "\n",
    "The RMSE values of 49k and 41k indicate our model is off by $410-490k on a given prediction on price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Error Contextualization**\n",
    "\n",
    "Regarding the MAE, an MAE of 270,000 is 20 percent of the average home value of 1.1 Million. \n",
    "\n",
    "Regarding the RMSE, an RMSE of 490,000 is 40 percent of the average home value of 1.1 Million. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylog_train = np.log(y_train)\n",
    "ylog_test = np.log(y_test)\n",
    "\n",
    "log_train_model = sm.OLS(ylog_train,sm.add_constant(X_train)).fit()\n",
    "log_test_model = sm.OLS(ylog_test,sm.add_constant(X_test)).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_train_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_test_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_train.params['basement_binary_grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_explain(column_list, model):\n",
    "    column_list.insert(0, 'const')\n",
    "    \n",
    "    for e in column_list:\n",
    "        log_val = model.params[e]\n",
    "        if log_val > 0:\n",
    "            print(f\"\"\"\n",
    "            A one-unit increase in the {e} variable corresponds\n",
    "            to an increase in price by a factor of {round(np.exp(log_val), 3)},\n",
    "            or {round(np.exp(log_val) - 1, 3)}%.\n",
    "            \"\"\") \n",
    "        else:\n",
    "            print(f\"\"\"\n",
    "            A one-unit increase in the {e} variable corresponds\n",
    "            to a decrease price to {round(np.exp(log_val), 3)}% of its prior value,\n",
    "            or a decrease of {round((log_val * 100), 3)}%.\n",
    "            \"\"\") \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_col = X_train.columns\n",
    "\n",
    "X_train_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_explain(X_train_col, log_train_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/kc_house_data.csv',\n",
    "                parse_dates=['date'])\n",
    "\n",
    "df.drop(['id', 'floors',\n",
    "         'heat_source','lat','long'], axis=1, inplace=True)\n",
    "\n",
    "# Create zip from address\n",
    "df['zip'] = [x.split(',')[2][-5:] for x in df['address']] \n",
    "\n",
    "#https://www.zillow.com/browse/homes/wa/king-county/  - remove all records with zipcodes that dont start with '98'\n",
    "\n",
    "df['city'] = [x.split(',')[1][0:] for x in df['address']]\n",
    "\n",
    "#create sale year column from datetime date info\n",
    "df['sale_year'] = pd.DatetimeIndex(df['date']).year.astype(int)\n",
    "\n",
    "df['sale_year'].value_counts()\n",
    "\n",
    "\n",
    "#create new column - age of house\n",
    "df['home_age'] = (df['sale_year']+1) - df['yr_built']\n",
    "\n",
    "#create new column - time since reno\n",
    "df['yr_from_reno'] = (df['sale_year']+1) - df['yr_renovated']\n",
    "\n",
    "# create filter for yr_from_reno to ID houses that haven't been renovated\n",
    "reno_filter = df['yr_from_reno'] > 2000\n",
    "\n",
    "# create new column for design_age to see time since build if no reno, or time since reno if renovated\n",
    "# first set to reno age\n",
    "df['design_age'] = df['yr_from_reno']\n",
    "#then update columns where there was no reno to age of the home\n",
    "df['design_age'].loc[reno_filter] = df['home_age']\n",
    "\n",
    "#some houses were sold before they were built - we need to change those records to 0\n",
    "\n",
    "prebuild_filter = df['design_age'] < 1\n",
    "\n",
    "df['design_age'].loc[prebuild_filter] = 1\n",
    "\n",
    "\n",
    "grade_cat = df[['grade']]\n",
    "grade_categories = ['1 Cabin', '2 Substandard', '3 Poor', '4 Low', '5 Fair', '6 Low Average',\n",
    "                    '7 Average', '8 Good', '9 Better', '10 Very Good', '11 Excellent', '12 Luxury', '13 Mansion']\n",
    "encoder_grade = OrdinalEncoder(categories=[grade_categories])\n",
    "encoder_grade.fit(grade_cat)\n",
    "grade_encoded_train = encoder_grade.transform(grade_cat)\n",
    "grade_encoded_train = grade_encoded_train.flatten()\n",
    "df[\"grade\"] = grade_encoded_train\n",
    "\n",
    "X_train = df\n",
    "\n",
    "# Quasi-categorical(0.5 + 0.5 bathrooms != 1 bathroom). Change 0 bathroom to 1 bathroom. Round up other values.\n",
    "X_train.loc[X_train['bathrooms'] == 0, 'bathrooms'] = 1\n",
    "X_train['bathrooms'] = X_train['bathrooms'].apply(np.ceil)\n",
    "\n",
    "\n",
    "# Create binary substitutes for columns\n",
    "X_train['basement_binary'] = [1 if sq >  0  else 0 for sq in X_train['sqft_basement']]\n",
    "X_train['garage_binary'] = [1 if sq >  0  else 0 for sq in X_train['sqft_garage']]\n",
    "X_train['patio_binary'] = [1 if sq >  0  else 0 for sq in X_train['sqft_patio']]\n",
    "X_train['waterfront_binary'] = [1 if sq == 'YES'  else 0 for sq in X_train['waterfront']]\n",
    "X_train['PublicSewer_binary'] = [1 if sq == 'PUBLIC' else 0 for sq in X_train['sewer_system']]\n",
    "X_train['yrenovated_binary'] = [1 if sq >  0 else 0 for sq in X_train['yr_renovated']]\n",
    "\n",
    "\n",
    "# Create binary values for greenbelt, nuisance\n",
    "# Using OneHotEncoder\n",
    "\n",
    "greenbelt_cat = X_train[['greenbelt']]\n",
    "encoder_greenbelt = OrdinalEncoder(categories=[['NO', 'YES']])\n",
    "encoder_greenbelt.fit(greenbelt_cat)\n",
    "greenbelt_encoded_train = encoder_greenbelt.transform(greenbelt_cat)\n",
    "greenbelt_encoded_train = greenbelt_encoded_train.flatten()\n",
    "# greenbelt_encoded_train\n",
    "X_train[\"greenbelt\"] = greenbelt_encoded_train\n",
    "\n",
    "nuisance_cat = X_train[['nuisance']]\n",
    "encoder_nuisance = OrdinalEncoder()\n",
    "encoder_nuisance.fit(nuisance_cat)\n",
    "nuisance_encoded_train = encoder_nuisance.transform(nuisance_cat)\n",
    "nuisance_encoded_train = nuisance_encoded_train.flatten()\n",
    "X_train[\"nuisance\"] = nuisance_encoded_train\n",
    "\n",
    "# Create Ordinal Values for condition\n",
    "# Using OneHotEncoder\n",
    "condition_cat = X_train[['condition']]\n",
    "condition_categories = ['Poor', 'Fair', 'Average', 'Good', 'Very Good']\n",
    "encoder_condition = OrdinalEncoder(categories=[condition_categories])\n",
    "encoder_condition.fit(condition_cat)\n",
    "condition_encoded_train = encoder_condition.transform(condition_cat)\n",
    "condition_encoded_train = condition_encoded_train.flatten()\n",
    "X_train[\"condition\"] = condition_encoded_train\n",
    "\n",
    "# Create Ordinal Values for view\n",
    "# Using OneHotEncoder\n",
    "view_cat = X_train[['view']]\n",
    "view_categories = ['NONE', 'FAIR', 'AVERAGE', 'GOOD', 'EXCELLENT']\n",
    "encoder_view = OrdinalEncoder(categories=[view_categories])\n",
    "encoder_view.fit(view_cat)\n",
    "view_encoded_train = encoder_view.transform(view_cat)\n",
    "view_encoded_train = view_encoded_train.flatten()\n",
    "X_train[\"view\"] = view_encoded_train\n",
    "\n",
    "\n",
    "# Create 'total_sqft' by combining sqft_above + sqft_basement + \n",
    "# sqft_garage + sqft_patio\n",
    "X_train['total_sqft'] = X_train['sqft_above'] + X_train['sqft_basement'] + X_train['sqft_garage'] + X_train['sqft_patio']\n",
    "\n",
    "X_train['weighted__livsqft'] = X_train['sqft_living'] * X_train['grade']\n",
    "\n",
    "X_train['date'] = pd.to_datetime(X_train['date'], format='%Y-%m-%d')\n",
    "\n",
    "X_train['date'].head()\n",
    "\n",
    "#create sale year column from datetime date info\n",
    "X_train['sale_year'] = pd.DatetimeIndex(X_train['date']).year.astype(int)\n",
    "\n",
    "X_train['sale_year'].value_counts()\n",
    "\n",
    "#Binning by decade\n",
    "\n",
    "X_train['design_decade'] = pd.cut(x=X_train['design_age'], bins=[0, 3, 13, 23, 33, 43, 53, 63, 73,\n",
    "                                                         83, 93, 103, 113, 123],\n",
    "                    labels=['2020s', '2010s', '2000s', '1990s', '1980s', '1970s', '1960s',\n",
    "                            '1950s', '1940s', '1930s', '1920s', '1910s', '1900s'])\n",
    "\n",
    "X_train.design_decade.value_counts()\n",
    "\n",
    "labels_ordered = ['2020s', '2010s', '2000s', '1990s', '1980s', '1970s', '1960s','1950s', '1940s', '1930s', '1920s', '1910s', '1900s']\n",
    "\n",
    "labels_ordered.reverse()\n",
    "\n",
    "labels_ordered\n",
    "\n",
    "# Create Ordinal Values for view\n",
    "# Using OneHotEncoder\n",
    "age_cat = X_train[['design_decade']]\n",
    "age_categories = labels_ordered\n",
    "encoder_age = OrdinalEncoder(categories=[age_categories])\n",
    "encoder_age.fit(age_cat)\n",
    "encoder_age.categories_[0]\n",
    "\n",
    "age_encoded_train = encoder_age.transform(age_cat)\n",
    "age_encoded_train = age_encoded_train.flatten()\n",
    "X_train[\"design_decade\"] = age_encoded_train\n",
    "\n",
    "X_train[\"design_decade\"]\n",
    "\n",
    "X_train['yard_size_ratio'] = (X_train['total_sqft'] / X_train['sqft_lot']) * 100\n",
    "\n",
    "X_train['view_grade'] = (X_train['view'] + 1) * X_train['grade']\n",
    "X_train['waterfront_grade'] = (X_train['waterfront_binary'] + 1)  * X_train['grade']\n",
    "X_train['design_decade_grade'] = (X_train['design_decade'] + 1)  * X_train['grade']\n",
    "X_train['nuisance_grade'] = (X_train['nuisance'] + 1)  * X_train['grade']\n",
    "X_train['garage_binary_grade'] = (X_train['garage_binary'] + 1)  * X_train['grade']\n",
    "X_train['basement_binary_grade'] = (X_train['basement_binary'] + 1)  * X_train['grade']\n",
    "X_train['patio_binary_grade'] = (X_train['patio_binary'] + 1)  * X_train['grade']\n",
    "X_train['PublicSewer_binary_grade'] = (X_train['PublicSewer_binary'] + 1)  * X_train['grade']\n",
    "X_train['condition_grade'] = (X_train['condition'] + 1)  * X_train['grade']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic spatial Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "relevant = ['price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement',\n",
    "            'sqft_garage', 'sqft_patio']\n",
    "\n",
    "basic_space = X_train[relevant]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_space_corr = basic_space.corr()\n",
    "\n",
    "basic_space_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr=X_train.corr().abs().stack().reset_index().sort_values(0, ascending=False)\n",
    "\n",
    "df_corr\n",
    "\n",
    "# zip the variable name columns (Which were only named level_0 and level_1 by default) in a new column named \"pairs\"\n",
    "df_corr['pairs'] = list(zip(df_corr.level_0, df_corr.level_1))\n",
    "\n",
    "# set index to pairs\n",
    "df_corr.set_index(['pairs'], inplace = True)\n",
    "\n",
    "#d rop level columns\n",
    "df_corr.drop(columns=['level_1', 'level_0'], inplace = True)\n",
    "\n",
    "# rename correlation column as cc rather than 0\n",
    "df_corr.columns = ['cc']\n",
    "\n",
    "# drop duplicates. This could be dangerous if you have variables perfectly correlated with variables other than themselves.\n",
    "# for the sake of exercise, kept it in.\n",
    "df_corr.drop_duplicates(inplace=True)\n",
    "\n",
    "df_corr[(df_corr.cc>.75) & (df_corr.cc <1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "# define the mask to set the values in the upper triangle to True\n",
    "mask = np.triu(np.ones_like(basic_space_corr, dtype=bool))\n",
    "heatmap = sns.heatmap(basic_space_corr, mask=mask, vmin=-1, vmax=1, annot=True)\n",
    "heatmap.set_title('Triangle Correlation Heatmap', fontdict={'fontsize':18}, pad=16)\n",
    "heatmap.set_facecolor('white');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corr = round(basic_space_corr,3)\n",
    "sns.set(rc = {'figure.figsize':(40,15)})\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "res = sns.heatmap(corr, mask=mask, vmin=-1, vmax=1, annot=True)\n",
    "res.set_xticklabels(res.get_xmajorticklabels(), fontsize = 15)\n",
    "res.set_yticklabels(res.get_ymajorticklabels(), fontsize = 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = round(basic_space_corr,3)\n",
    "sns.set(rc = {'figure.figsize':(40,15)})\n",
    "sns.heatmap(corr, cmap=\"Reds\", annot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Engineered spatial Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "relevant = ['price', 'total_sqft', 'weighted__livsqft', 'sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement',\n",
    "            'sqft_garage', 'sqft_patio']\n",
    "\n",
    "eng_space = X_train[relevant]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_space_corr = eng_space.corr()\n",
    "\n",
    "eng_space_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = round(eng_space_corr,3)\n",
    "sns.set(rc = {'figure.figsize':(50,18)})\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "res = sns.heatmap(corr, mask=mask, vmin=-1, vmax=1, annot=True)\n",
    "res.set_xticklabels(res.get_xmajorticklabels(), fontsize = 12)\n",
    "res.set_yticklabels(res.get_ymajorticklabels(), fontsize = 12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant = ['price', 'waterfront', 'greenbelt', 'nuisance', 'view', 'condition', 'grade','basement_binary', 'garage_binary',\n",
    "            'patio_binary', 'waterfront_binary', 'PublicSewer_binary', 'yrenovated_binary','design_decade']\n",
    "\n",
    "bas_cat = X_train[relevant]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bas_cat_corr = bas_cat.corr()\n",
    "\n",
    "bas_cat_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = round(bas_cat_corr,3)\n",
    "sns.set(rc = {'figure.figsize':(50,18)})\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "res = sns.heatmap(corr, mask=mask, vmin=-1, vmax=1, annot=True)\n",
    "res.set_xticklabels(res.get_xmajorticklabels(), fontsize = 12)\n",
    "res.set_yticklabels(res.get_ymajorticklabels(), fontsize = 12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "engineered categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant = ['price', 'view_grade', 'waterfront_grade', 'design_decade_grade',\n",
    "            'nuisance_grade', 'garage_binary_grade', 'basement_binary_grade',\n",
    "            'patio_binary_grade', 'PublicSewer_binary_grade', 'condition_grade']\n",
    "\n",
    "eng_cat = X_train[relevant]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_cat_corr = eng_cat.corr()\n",
    "\n",
    "eng_cat_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = round(eng_cat_corr,3)\n",
    "sns.set(rc = {'figure.figsize':(50,18)})\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "res = sns.heatmap(corr, mask=mask, vmin=-1, vmax=1, annot=True)\n",
    "res.set_xticklabels(res.get_xmajorticklabels(), fontsize = 12)\n",
    "res.set_yticklabels(res.get_ymajorticklabels(), fontsize = 12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Messing Around - weights of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant = [' Auburn', ' Bellevue', ' Black Diamond', ' Bothell', ' Burien',\n",
    "           ' Carnation', ' Clyde Hill', ' Covington', ' Des Moines', ' Duvall',\n",
    "           ' Enumclaw', ' Fall City', ' Federal Way', ' Issaquah', ' Kenmore',\n",
    "           ' Kent', ' Kirkland', ' Lake Forest Park', ' Maple Valley', ' Medina',\n",
    "           ' Mercer Island', ' Newcastle', ' Normandy Park', ' North Bend',\n",
    "           ' Pacific', ' Ravensdale', ' Redmond', ' Renton', ' Sammamish',\n",
    "           ' SeaTac', ' Seattle', ' Shoreline', ' Snoqualmie', ' Tukwila',\n",
    "           ' Vashon', ' Woodinville',\n",
    "            'weighted__livsqft', 'design_decade', 'yard_size_ratio', 'view_grade',\n",
    "            'waterfront_grade', 'design_decade_grade', 'nuisance_grade', 'garage_binary_grade',\n",
    "            'basement_binary_grade', 'patio_binary_grade', 'PublicSewer_binary_grade', 'condition_grade']\n",
    "\n",
    "X_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_standard = X_train.apply(lambda x: (x-x.mean())/ x.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_standardized = sm.OLS(y, sm.add_constant(X_standard)).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = results_standardized.params.abs.sort_values()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(y = weights[1::].index, x = weights[1::].values)\n",
    "plt.title(\"Weights for factors correlating with sale price\")\n",
    "plt.ylabel('Weight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
